<!doctype html><html lang=en-us><head><title>Execution time | berfr blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=canonical href=https://berfr.me/posts/execution-time/><link rel=stylesheet href=/css/styles.min.css></head><body><header><h2><a href=/>berfr blog</a></h2></header><hr><article class=post><header><h1>Execution time</h1><div class=post-time>Posted on April 30, 2020.
Last modified on May 01, 2020.</div></header><p>Consider this Python program:</p><div class=highlight><pre class=chroma><code class=language-python3 data-lang=python3><span class=c1># num_add.py</span>

<span class=n>ans</span> <span class=o>=</span> <span class=mi>0</span>

<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>123456789</span><span class=p>):</span>
    <span class=n>ans</span> <span class=o>+=</span> <span class=mi>1</span>

<span class=nb>print</span><span class=p>(</span><span class=n>ans</span><span class=p>)</span>
</code></pre></div><p>It runs in a little over 10 seconds:</p><pre><code class=language-console data-lang=console>$ time python num_add.py
123456789

real    0m12.896s
user    0m12.868s
sys     0m0.008s
</code></pre><p>This result is expected; it takes a certain amount of time to perform more than
one hundred million additions. During this, my computer was working hard; the
fans started going pretty fast.</p><p>Now consider this Python program:</p><div class=highlight><pre class=chroma><code class=language-python3 data-lang=python3><span class=c1># sleep.py</span>

<span class=kn>import</span> <span class=nn>time</span>

<span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mf>12.8</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=mi>123456789</span><span class=p>)</span>
</code></pre></div><p>It executes in about the same amount of time and outputs the same thing:</p><pre><code class=language-console data-lang=console>$ time python sleep.py
123456789

real    0m12.847s
user    0m0.026s
sys     0m0.008s
</code></pre><p>This time though, my computer was completely silent during the execution. As if
nothing was being done. If you look at the source of <a href=https://github.com/python/cpython/blob/62183b8d6d49e59c6a98bbdaa65b7ea1415abb7f/Modules/timemodule.c#L326><code>time.sleep</code></a>, and to the
called cross platform <a href=https://github.com/python/cpython/blob/62183b8d6d49e59c6a98bbdaa65b7ea1415abb7f/Modules/timemodule.c#L1859><code>pysleep</code></a> function, you will see that the underlying
mechanism for wasting time is a call to <a href=https://linux.die.net/man/3/select><code>select</code></a> with no watched file
descriptor sets and the desired timeout. From this point, it is up to the
operating system to return when the amount of time is elapsed.</p><p>The actual CPU time can be seen in the values returned by the <a href=https://linux.die.net/man/1/time><code>time</code></a> command.
The <code>user</code> and <code>sys</code> parts is the time that was taken for running code in
user-mode and in kernel-mode respectively. The first program spent all the time
running code whereas the second spent almost no time running code. While they
have the same behavior, it could be argued that the second script is better
since it leaves CPU time for the OS to perform more important tasks.</p><p>We will now test out a similar program in C:</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=c1>// num_add.c
</span><span class=c1></span>
<span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span><span class=cp></span>
<span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
    <span class=kt>int</span> <span class=n>ans</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>

    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=mi>123456789</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
        <span class=n>ans</span> <span class=o>+=</span> <span class=mi>1</span><span class=p>;</span>
    <span class=p>}</span>

    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ans</span><span class=p>);</span>
<span class=p>}</span>
</code></pre></div><p>This one has a more surprising execution time:</p><pre><code class=language-console data-lang=console>$ gcc num_add.c
$ time ./a.out
123456789

real    0m0.296s
user    0m0.294s
sys     0m0.002s
</code></pre><p>The computation time is a fraction of a second. At first, I was certain a
compiler optimization had avoided the computation and just printed the obvious
result. By inspecting the Assembly for this program, we can see that the loop
and arithmetic is actually performed:</p><div class=highlight><pre class=chroma><code class=language-asm data-lang=asm><span class=na>...</span>
<span class=err>40113</span><span class=nl>e:</span>       <span class=err>83</span> <span class=err>45</span> <span class=nf>fc</span> <span class=mi>01</span>             <span class=no>addl</span>   <span class=no>$0x1</span><span class=p>,-</span><span class=mi>0x4</span><span class=p>(</span><span class=nv>%rbp</span><span class=p>)</span>
<span class=err>401142:</span>       <span class=err>83</span> <span class=err>45</span> <span class=nf>f8</span> <span class=mi>01</span>             <span class=no>addl</span>   <span class=no>$0x1</span><span class=p>,-</span><span class=mi>0x8</span><span class=p>(</span><span class=nv>%rbp</span><span class=p>)</span>
<span class=err>401146:</span>       <span class=err>81</span> <span class=err>7</span><span class=nf>d</span> <span class=no>f8</span> <span class=mi>14</span> <span class=no>cd</span> <span class=mi>5</span><span class=no>b</span> <span class=mi>07</span>    <span class=no>cmpl</span>   <span class=no>$0x75bcd14</span><span class=p>,-</span><span class=mi>0x8</span><span class=p>(</span><span class=nv>%rbp</span><span class=p>)</span>
<span class=err>40114</span><span class=nl>d:</span>       <span class=err>7</span><span class=nf>e</span> <span class=no>ef</span>                   <span class=no>jle</span>    <span class=mh>40113e</span> <span class=p>&lt;</span><span class=no>main</span><span class=p>+</span><span class=mi>0x18</span><span class=p>&gt;</span>
<span class=na>...</span>
</code></pre></div><p>I was aware of overhead in interpreted languages such as Python but never
thought it would be this obvious.</p><p>This simple experiment shows how execution time varies in very similar programs.
I would much prefer waiting only 0.2 seconds rather than 12 for my computations
to complete. At the same time, I would choose writing in a higher level
programming language any day. As with many other things in life, it is a matter
of tradeoffs.</p></article><hr><footer><p><a href=https://github.com/berfr>GitHub</a> /
<a href=https://git.sr.ht/~berfr>SourceHut</a></p><p><a href=/publickey.txt>67CA4E4F727349D3</a></p><p><a href=mailto:me@berfr.me>me@berfr.me</a></p><p><a href=/index.xml>RSS</a></p></footer></body></html>